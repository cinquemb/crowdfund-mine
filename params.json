{"name":"Crowdfund-Mine","tagline":"General experiment to mine social media data in context of crowdfunding","body":"## Mining Social Media Data In Context of Crowdfunding Data - Part 1: Social Side\r\n\r\nTrying to figure out the effectiveness of one’s efforts for fundraising can be a pretty arduous task online(so I'm told), especially if one is not equipped with the mindset of what would be a way to measure such. Not only that, analyzing datasets like these can help individuals and organizations identify exactly who is their audience, who in their audience has the most potential for helping launch/sustain/grow campaigns, and see how these things can change over the lifetime of one or more campaigns.\r\n\r\n### The Challenge\r\n\r\nThis challenge came to me from a cousin of mine who works for a non-profit in Houston, TX ([Neighborhood Centers Inc](http://iamforgood.org/)) where he was wondering if it was possible to be able to measure how effective any crowdfunding campaign could be in general, over time. One of the modern hallmarks of crowdfunding is to usually rely on sites like kickstarter and indigogo, so I knew where I would start.\r\n\r\n### Getting Started\r\n\r\nWhile getting started, my initial mindset was to figure out how to get social data without needing API access. API access is a drag on experiments like these because it takes away the time you could be coding up a solution, and because Information Wants To Be Free™. So that pretty much immediately put Facebook out of the race (for now) and left me with Twitter. On Twitter, you can search for whatever you want publicly. Using this functionality, I opened up the console in Firefox and looked for HTTP requests made that could simplify a future scrape...\r\n\r\nJackpot: \r\n\r\n```https://twitter.com/i/search/timeline?q=%s&composed_count=1&include_available_features=1&include_entities=1&include_new_items_bar=true&interval=1&f=realtime' % (some_query_of_interest)```\r\n\r\n…which returns a bunch of tweets that include “some_query_of_interest” in ```json``` format\r\n\r\n### What Data To Mine\r\n\r\nSince I'm starting out with social data, I wanted to mine data that would possibly signal the effectiveness of a crowdfunding campaign online (on Twitter).  So on twitter that would be tweets that contain links (possibly to the crowdfunding site and filtering out those that don’t contain any), who tweeted the original link at what time, how many re-tweets and favorites (at what time) and from who. The 'who' is this case will be a twitter user id which will allow us to go back retroactively to obtain information such as how many followers they have and etc. During this process I somewhat tried to minimize the amount of requests I made to twitter, though I suspect that most of the time is spent in processing since some of the operations are O(n^2) and O(n^3).\r\n\r\nAs to obtain this data for an individual tweet:\r\n\r\ntweet url: ``` ‘https://twitter.com/i/status/%s' % (tweet_id) ```\r\n\r\nretweet-data: ``` 'https://twitter.com/i/activity/retweeted_popup?id=%s' % (tweet_id) ```\r\n\r\nfavorite-data: ``` 'https://twitter.com/i/activity/favorited_popup?id=%s' % (tweet_id) ```\r\n\r\n### How To Mine For Yourself\r\n\r\nI'm doing this in python using virtualenv, but this can be done in any language of your choosing. Here are my steps:\r\n\r\n```\r\n1) $ git clone https://github.com/cinquemb/crowdfund-mine.git\r\n2) $ cd ../path/to/crowdfund-mine/\r\n3) $ virtualenv env --distribute\r\n4) $ source env/bin/activate\r\n5) $ mkdir mined_data\r\n6) $ mkdir final_mined_data\r\n7) $ pip install -r ops/requirements.txt\r\n8) Edit line 25 in social-mine.py to your choosing for queries that are of interest to you in respect to this topic as of now it is set to: crowdsource_site_list = ['startsomegood', 'indigogo', 'kickstarter']\r\n9) $ python social-mine.py\r\n```\r\n\r\nLast command will generate a ```json``` file in ```mined_data/``` directory, where you can do what you want with it.\r\nThe data in the generated files will look something like below for every tweet:\r\n\r\n```\r\n{\r\n    \"query\": \"startsomegood\",\r\n    \"user\": 18086787,\r\n    \"time_created\": 1386460857,\r\n    \"tweet_id\": 409472628903378940,\r\n    \"urls\": \"['http://ow.ly/r3Za8'],['http://ow.ly/r3ZC5'],\",\r\n    \"data\": [\r\n        {\r\n            \"metadata\": [\r\n                {\r\n                    \"retweets\": 2\r\n                },\r\n                {\r\n                    \"favorites\": 2\r\n                },\r\n                {\r\n                    \"retweet-metadata\": [\r\n                        {\r\n                            \"user\": 17877757\r\n                        },\r\n                        {\r\n                            \"user\": 15247690\r\n                        }\r\n                    ]\r\n                },\r\n                {\r\n                    \"favorite-metadata\": [\r\n                        {\r\n                            \"user\": 17877757\r\n                        },\r\n                        {\r\n                            \"user\": 1705181065\r\n                        }\r\n                    ]\r\n                }\r\n            ]\r\n        }\r\n    ]\r\n}\r\n```\r\nThis command has taken me anywhere from 44s to 57s to run (duration is printed at end of script), and can be run on an interval of your choosing (with something like cron).\r\n\r\n### What's Next?\r\n\r\nMy next objective is to work on ```crowdfund-mine.py``` which will follow the link(s) contained in the tweet to see if it is a crowdfunding site and scrape data from the page and associate it with the tweet (and it's data). If anyone has any suggestions/ideas about any of this, feel free to send me an email.\r\n\r\n### Author(s)/Contributor(s)\r\nMe: @cinquemb\r\n\r\n### Contact\r\nYou can reach me at NSA's favorite email service with my github username [at] gmail.com","google":"","note":"Don't delete this file! It's used internally to help with page regeneration."}